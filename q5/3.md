
## 1. 场景与符号（题目三对齐）

本节面向题目三：多微基站、同频复用存在相互干扰，需同时进行每 100 ms 的资源块（RB）划分与切片功率控制，使整体用户服务质量（QoS）最大化。实现基于 `q3` 目录中的环境与多智能体强化学习。

### 1.1 集合与索引
- \( \mathcal{B} = \{\text{BS1},\text{BS2},\text{BS3}\} \)：微基站集合
- \( \mathcal{S} = \{\text{URLLC}, \text{eMBB}, \text{mMTC}\} \)：切片集合
- \( \mathcal{K}_s \)：切片 \(s\) 的用户集合（来自数据集）
- \( t \in \{0,1,\dots,9\} \)：决策周期索引（每 100 ms，共 10 次）

### 1.2 参数（与实现一致）
- \( RB^{\text{total}}_n = 50 \)：每个微基站的总 RB 数
- \( b = 360\,\text{kHz} \)：单 RB 带宽
- \( \phi_{n,k}(t) \)：大规模衰减（dB），来自 `data_3/BSx_大规模衰减.csv`
- \( h_{n,k}(t) \)：小规模瑞利衰减，来自 `data_3/BSx_小规模瑞丽衰减.csv`
- 噪声谱密度 \(-174\,\text{dBm/Hz}\)，噪声系数 \(NF=7\,\text{dB}\)
- 功率等级：\(p_{n,s}(t) \in \{10,20,30\}\,\text{dBm}\)
- SLA 与单位 RB 粒度（来自实现中的 `slice_params`）：
  - URLLC：\(\text{rb\_unit}=10\), \(r_{\text{SLA}}=10\,\text{Mbps}\), \(L_{\text{SLA}}=5\,\text{ms}\), 惩罚 5，\(\alpha=0.95\)
  - eMBB：\(\text{rb\_unit}=5\), \(r_{\text{SLA}}=50\,\text{Mbps}\), \(L_{\text{SLA}}=100\,\text{ms}\), 惩罚 3
  - mMTC：\(\text{rb\_unit}=2\), \(r_{\text{SLA}}=1\,\text{Mbps}\), \(L_{\text{SLA}}=500\,\text{ms}\), 惩罚 1

### 1.3 决策与接入（与实现一致）
- 每个基站在时刻 \(t\) 同时决定一个 RB 三元组与功率三元组：
  - \( \mathbf{r}_n(t)=(RB_{n,\text{URLLC}}, RB_{n,\text{eMBB}}, RB_{n,\text{mMTC}}) \)
  - \( \mathbf{p}_n(t)=(p_{n,\text{URLLC}}, p_{n,\text{eMBB}}, p_{n,\text{mMTC}}) \)
- 用户接入：每个时刻将每名用户分配给“等效增益”最大的基站（实现采用 \(10^{\phi/10}+|h|^2\) 的线性合并用于排序）。

---

## 2. 信道、干扰与速率（实现等式）

### 2.1 接收功率（mW）
\[
p_{\text{rx}}(n,k,t) 
\;=\; 10^{\frac{p_{n,s(k)}(t) - \phi_{n,k}(t)}{10}} \cdot |h_{n,k}(t)|^2
\]
其中 \(s(k)\) 为用户所属切片。

### 2.2 干扰（同切片跨基站）
\[
I_{n,k}(t) 
\;=\; \sum_{\substack{u\in\mathcal{B}\\u\neq n}} 10^{\frac{p_{u,s(k)}(t) - \phi_{u,k}(t)}{10}} \cdot |h_{u,k}(t)|^2
\]

### 2.3 噪声与信干噪比
\[
N_0\,\text{(dBm)} = -174 + 10\log_{10}(i_k\,b) + NF,\quad 
\text{SINR}_{n,k}(t) = \frac{p_{\text{rx}}(n,k,t)}{I_{n,k}(t) + N_0\,(\text{mW})}
\]
其中 \(i_k\) 为该用户本次分配的 RB 数（实现中按切片单位分配），\(N_0\) 转线性再参与分母。

### 2.4 速率（Mbps）
\[
r_{n,k}(t) = i_k\,b\,\log_2(1+\text{SINR}_{n,k}(t)) / 10^6
\]

---

## 3. QoS 定义（与实现一致）

### 3.1 URLLC
\[
y^{\text{URLLC}}_k(t) = \begin{cases}
\alpha^{L_k(t)}, & L_k(t) \le L_{\text{SLA}}^{\text{URLLC}} \\
-5, & \text{否则}
\end{cases}
\]

### 3.2 eMBB
\[
y^{\text{eMBB}}_k(t) = \begin{cases}
1, & r_{n,k}(t) \ge 50\,\text{Mbps} \\
\max\big(0, \tfrac{r_{n,k}(t)}{50}\big), & r_{n,k}(t) < 50\,\text{Mbps}
\end{cases}
\]

### 3.3 mMTC（接入成功判定）
\[
y^{\text{mMTC}}_k(t) = \mathbb{I}\{r_{n,k}(t) \ge 1\,\text{Mbps}\}
\]

---

## 4. 约束与动作空间

1) RB 容量与粒度（离散）：\(\sum_s RB_{n,s}(t) \le 50\)，且分别为 \(10/5/2\) 的倍数。

2) 功率等级（离散）：\(p_{n,s}(t) \in \{10,20,30\}\,\text{dBm}\)。

3) 用户接入唯一：每名用户每次仅接入一个基站（由等效增益准则决定）。

动作空间在实现中由所有合法的 RB 三元组与功率三元组的笛卡尔积构成，供智能体选择。

---

## 5. 多智能体强化学习求解

### 5.1 环境与观测
- 环境：`MultiBSInterferenceEnv`（`data_3` 数据，决策 10 次）。
- 观测：对每个基站提供拼接向量，包含切片队列统计（长度、平均等待、紧急比）、代表性用户信道增益特征、归一化时间。
- 队列演化：按 100 ms 推进，超过各切片 SLA 的排队任务将带来额外惩罚。

### 5.2 智能体与学习
- 架构：每个基站一个线性函数近似 Q-learning 智能体，联合动作为（RB 索引，功率索引）。
- 策略：epsilon-greedy；价值更新按 \(Q(s,a)=w_a^\top s\) 线性近似；全局奖励回传给所有智能体。
- 奖励：当次决策内被服务任务的平均 QoS，叠加“队列超时惩罚”（URLLC 权重更大）。

### 5.3 训练与评估流程
- 训练脚本：`q3/q3_train.py`（可配置回合数）。
- 评估脚本：`q3/q3_eval.py`（贪心评估，导出每次决策的 RB/功率与奖励到 `q3_eval_decisions.csv`）。
- 可视化：`q3/q3_plot.py` 读取评估 CSV，输出 `q3_plots/` 下的奖励曲线、各基站 RB 堆叠图与功率轨迹图。

---

## 6. 复现实验步骤

1) 训练（可调 `num_episodes`）：
```bash
python q3/q3_train.py
```
2) 评估并导出决策：
```bash
python q3/q3_eval.py
```
3) 生成图表：
```bash
python q3/q3_plot.py --csv q3_eval_decisions.csv --outdir q3_plots
```

---

## 7. 结果解读（基于评估与作图）

- 奖励随决策的变化反映了调度与功率联动对平均 QoS 的影响，奖励抖动通常源于干扰与队列状态随机性。
- 各基站 RB 堆叠图展示了切片间资源在 50 RB 内的时序分配，URLLC 通常以 10 RB 粒度调度以满足严格时延。
- 功率曲线限定在 \{10,20,30\} dBm：当跨站干扰增强时，智能体可能降低部分切片功率或调整 RB 以权衡 SINR 与速率。

（具体数值结果以 `q3_eval_decisions.csv` 与 `q3_plots/` 导出的图表为准。）

---

## 8. 与题目三的一致性说明

- 同频复用与干扰：干扰按附录给出的同切片跨基站功率叠加模型计算，噪声按 \(-174\,\text{dBm/Hz}\) 与 \(NF=7\,\text{dB}\) 计算。
- 决策周期：每 100 ms 决策一次，共 10 次（1000 ms）。
- 决策输出：每基站的切片 RB 划分与功率控制同时输出。
- QoS 评价：严格遵循 URLLC/eMBB/mMTC 的 SLA 约束与实现中的打分规则。

---

## 9. 可能的拓展改进

- 引入双重 DQN 或策略梯度以提升函数逼近能力，减小离散动作表的维度压力。
- 在奖励中引入能耗权衡项，为题目四、五的能效优化打基础。
- 更精细的用户级 RB 分配与连续功率控制（需结合稳定训练技巧）。
